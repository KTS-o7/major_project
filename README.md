# major_project

## SYNOPSIS

### INTRODUCTION:

This project investigates the application of Large Language Models (LLMs) for efficient log summarization. Log files, critical for system monitoring and debugging, often contain vast amounts of information that are difficult to manually analyze. This research focuses on developing a customized fine-tuning dataset of logs and their corresponding summaries. By leveraging this dataset, we will fine-tune a range of LLMs, spanning from 50 million to 8 billion parameters, to assess their ability to generate concise and accurate log summaries. The effectiveness of these fine-tuned models will be rigorously evaluated using metrics such as BLEU, ROUGE, METEOR, and BERTScore, providing insights into the scalability and performance of LLMs for log summarization tasks.

### OBJECTIVE:

- To develop a custom fine-tuning dataset comprising logs and their corresponding summaries.
- To fine-tune various Large Language Models (LLMs) ranging from 50M to 8B parameters using the created dataset.
- To evaluate the performance of the fine-tuned LLMs in log summarization using evaluation metrics such as BLEU, ROUGE, METEOR, and BERTScore.

### METHODOLOGY:

- Dataset Creation: Construct a comprehensive dataset of log files and their human-written summaries, ensuring diversity and quality of data.
  Model Fine-Tuning: Implement fine-tuning procedures for LLMs of varying sizes (50M to 8B parameters) using the prepared dataset.
- Evaluation: Apply evaluation metrics, including BLEU, ROUGE, METEOR, and BERTScore, to assess the accuracy and efficiency of the log summarization generated by the fine-tuned models.
- Comparative Analysis: Compare the performance of different LLMs based on their size and fine-tuning results, identifying the optimal model size for effective log summarization.

### Software Requirements:

- Python (3.13.x)
- PyTorch (for model training and fine-tuning)
- Hugging Face Transformers library (for accessing and utilizing pre-trained models)
- Ollama server (for running and managing LLMs)
- Libraries for evaluation metrics (e.g., BLEU, ROUGE, METEOR, BERTScore implementations)
- Libraries for data processing and manipulation (e.g., Pandas, NumPy)

### Hardware Requirements:

- A100 GPUs
- 64GB+ RAM
- 500GB HDD/SSD
- Linux based Operating System

### INNOVATION / CONTRIBUTION TO THE FIELD:

- Optimal Model Size Recommendation for Enterprise Log Handling: The research will provide insights into the trade-offs between model size and performance for log summarization in an enterprise setting. By comparing the effectiveness of smaller fine-tuned models versus larger general-purpose models, the study will offer practical recommendations on the optimal model size and deployment strategy for efficient and cost-effective log management in real-world scenarios.
- Comparative Analysis of Fine-Tuned vs. Non-Fine-Tuned LLMs: The project will conduct a detailed comparative analysis of the performance of fine-tuned LLMs against their non-fine-tuned counterparts. This analysis will map how accuracy and other relevant parameters scale with model size and fine-tuning, providing valuable data on the benefits and impact of domain-specific fine-tuning for log summarization tasks.
- Provision of a High-Quality Annotated Dataset and Evaluation Set: A significant contribution of this project will be the creation and public release of a high-quality, annotated dataset of logs and their summaries, along with a dedicated evaluation set. This resource will enable other researchers to replicate and extend this research, fostering further advancements in the field of LLM-based log analysis and promoting open science practices.
